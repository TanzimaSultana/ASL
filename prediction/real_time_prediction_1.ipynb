{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69cad08-6632-4594-a1a6-753380e8159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf92ae8f-9322-4fb6-993f-f09ca7d2894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd37ac91-43a8-4270-b919-ab6224f0a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "\n",
    "# Load the trained model\n",
    "model_path_cnn = os.path.abspath(\"../model/cnn.keras\")\n",
    "cnn_model = tf.keras.models.load_model(model_path_cnn)\n",
    "\n",
    "model_path_cnn1 = os.path.abspath(\"../model/cnn_1.keras\")\n",
    "cnn_aug_model = tf.keras.models.load_model(model_path_cnn1)\n",
    "\n",
    "model_path_vgg16 = os.path.abspath(\"../model/vgg16.keras\")\n",
    "vgg16_model = tf.keras.models.load_model(model_path_vgg16)\n",
    "\n",
    "model_path_vgg16_1 = os.path.abspath(\"../model/vgg16_finetuned.keras\")\n",
    "vgg16_1_model = tf.keras.models.load_model(model_path_vgg16_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dcb1481-e5c3-4043-b33f-b6ce234ee16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 12:20:05.207856: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] PluggableGraphOptimizer failed: INVALID_ARGUMENT: Failed to deserialize the `graph_buf`.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Labels used during training\n",
    "labels = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") + [\"space\", \"del\", \"nothing\"]\n",
    "IMG_SIZE = 64\n",
    "\n",
    "# Webcam setup\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# GUI Setup\n",
    "root = tk.Tk()\n",
    "root.title(\"ASL Prediction GUI\")\n",
    "root.geometry(\"820x540\")  # Adjust window height\n",
    "\n",
    "video_frame = tk.Label(root)\n",
    "video_frame.pack(pady=10)\n",
    "\n",
    "capture_btn = tk.Button(root, text=\"ðŸ“· Capture\", font=(\"Helvetica\", 14), command=lambda: capture_and_predict())\n",
    "capture_btn.pack(pady=10)\n",
    "\n",
    "overlay_roi = None\n",
    "overlay_text = \"\"\n",
    "\n",
    "def draw_bounding_box(frame, box_size=250):\n",
    "    h, w, _ = frame.shape\n",
    "    x1 = w // 2 - box_size // 2\n",
    "    y1 = h // 2 - box_size // 2\n",
    "    x2 = x1 + box_size\n",
    "    y2 = y1 + box_size\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return frame, (x1, y1, x2, y2)\n",
    "\n",
    "def update_webcam():\n",
    "    global overlay_roi, overlay_text\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame, _ = draw_bounding_box(frame)\n",
    "\n",
    "    # Overlay ROI preview and prediction text\n",
    "    if overlay_roi is not None:\n",
    "        roi_resized = cv2.resize(overlay_roi, (100, 100))\n",
    "        frame[10:110, 10:110] = roi_resized  # Top-left\n",
    "\n",
    "        if overlay_text:\n",
    "            y_offset = 120\n",
    "            for line in overlay_text.strip().split(\"  \"):\n",
    "                cv2.putText(frame, line.strip(), (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.45, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                y_offset += 18\n",
    "\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = ImageTk.PhotoImage(Image.fromarray(img))\n",
    "    video_frame.configure(image=img)\n",
    "    video_frame.image = img\n",
    "    root.after(10, update_webcam)\n",
    "\n",
    "def predict_from_models(frame, box_coords):\n",
    "    preds = {}\n",
    "\n",
    "    # CNN and AugCNN (grayscale, 64x64, 1)\n",
    "    x1, y1, x2, y2 = box_coords\n",
    "    roi_gray = cv2.cvtColor(frame[y1:y2, x1:x2], cv2.COLOR_BGR2GRAY)\n",
    "    roi_gray_resized = cv2.resize(roi_gray, (64, 64))\n",
    "    roi_gray_normalized = roi_gray_resized.astype(\"float32\") / 255.0\n",
    "    roi_gray_input = np.expand_dims(roi_gray_normalized, axis=(0, -1))  # (1, 64, 64, 1)\n",
    "\n",
    "    for model_name, model in [(\"CNN\", cnn_model), (\"AugCNN\", cnn_aug_model)]:\n",
    "        prob = model.predict(roi_gray_input, verbose=0)[0]\n",
    "        pred_idx = np.argmax(prob)\n",
    "        preds[model_name] = (labels[pred_idx], prob[pred_idx])\n",
    "\n",
    "    # VGG models (RGB, 96x96, 3)\n",
    "    roi_rgb = cv2.cvtColor(frame[y1:y2, x1:x2], cv2.COLOR_BGR2RGB)\n",
    "    roi_rgb_resized = cv2.resize(roi_rgb, (96, 96))\n",
    "    roi_rgb_normalized = roi_rgb_resized.astype(\"float32\") / 255.0\n",
    "    roi_rgb_input = np.expand_dims(roi_rgb_normalized, axis=0)  # (1, 96, 96, 3)\n",
    "\n",
    "    for model_name, model in [(\"VGG16\", vgg16_model), (\"VGG16_FT\", vgg16_1_model)]:\n",
    "        prob = model.predict(roi_rgb_input, verbose=0)[0]\n",
    "        pred_idx = np.argmax(prob)\n",
    "        preds[model_name] = (labels[pred_idx], prob[pred_idx])\n",
    "\n",
    "    return preds\n",
    "\n",
    "def capture_and_predict():\n",
    "    global overlay_roi, overlay_text\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        messagebox.showerror(\"Error\", \"Failed to read from webcam.\")\n",
    "        return\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_boxed, box_coords = draw_bounding_box(frame)\n",
    "\n",
    "    # Save ROI\n",
    "    x1, y1, x2, y2 = box_coords\n",
    "    overlay_roi = frame_boxed[y1:y2, x1:x2]\n",
    "\n",
    "    # Predict\n",
    "    predictions = predict_from_models(frame, box_coords)\n",
    "    overlay_text = \"\"\n",
    "    for model, (label, conf) in predictions.items():\n",
    "        overlay_text += f\"{model}: {label} ({conf:.2f})  \"\n",
    "\n",
    "def on_close():\n",
    "    cap.release()\n",
    "    root.destroy()\n",
    "\n",
    "root.protocol(\"WM_DELETE_WINDOW\", on_close)\n",
    "\n",
    "# Start\n",
    "update_webcam()\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e7411-183a-4887-bf33-6edcac3e3ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
